{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 7 - Distinguishing Sentiments\n",
    "The first plot will be and/or feature the following:\n",
    "\n",
    "* Be a scatter plot of sentiments of the last 100 tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "* Each plot point will reflect the compound sentiment of a tweet.\n",
    "* Sort each plot point by its relative timestamp.\n",
    "* The second plot will be a bar plot visualizing the overall sentiments of the last 100 tweets from each organization. For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n",
    "The tools of the trade you will need for your task as a data analyst include the following: tweepy, pandas, matplotlib, and VADER.\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "* Pull last 100 tweets from each outlet.\n",
    "* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet. \n",
    "* Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "* Export the data in the DataFrame into a CSV file.\n",
    "* Save PNG images for each plot.\n",
    "\n",
    "As final considerations:\n",
    "\n",
    "* Use the Matplotlib libraries.\n",
    "* Include a written description of three observable trends based on the data. \n",
    "* Include proper labeling of your plots, including plot titles (with date of analysis) and axes labels.\n",
    "* Include an exported markdown version of your Notebook called README.md in your GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import tweepy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from config import (consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup Tweepy API authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Target Twitter Accounts\n",
    "target_terms = (\"@BBC\", \"@CBS\", \"@CNN\", \"@FOXNEWS\", \"@NYTIMES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out non-human activity\n",
    "min_tweets = 5\n",
    "max_tweets = 10000\n",
    "max_followers = 2500\n",
    "max_following = 2500\n",
    "lang = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to hold sentiment\n",
    "sentiments = []\n",
    "\n",
    "counter = 1\n",
    "\n",
    "# Loop through target accounts\n",
    "for target in target_terms:\n",
    "    oldest_tweet = None\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    neutral_list = []\n",
    "    negative_list = []\n",
    "    \n",
    "    # Loop through range to obtain the last 100 tweets by each account\n",
    "    for loop in range(4):\n",
    "        public_tweets = api.search(target, count=100, result_type=\"recent\", max_id=oldest_tweet)\n",
    "        for tweet in public_tweets[\"statuses\"]:\n",
    "            # Utilize the non-human filters\n",
    "            if (tweet[\"user\"][\"followers_count\"] < max_followers and\n",
    "                tweet[\"user\"][\"statuses_count\"] > min_tweets and\n",
    "                tweet[\"user\"][\"statuses_count\"] < max_tweets and\n",
    "                tweet[\"user\"][\"friends_count\"] < max_following and\n",
    "                tweet[\"user\"][\"lang\"] == lang):\n",
    "                \n",
    "                #Run VADER Analysis on each tweet\n",
    "                results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "                compound = results[\"compound\"]\n",
    "                pos = results[\"pos\"]\n",
    "                neu = results[\"neu\"]\n",
    "                neg = results[\"neg\"]\n",
    "                tweets_ago = counter\n",
    "                \n",
    "                # Push to each array\n",
    "                compound_list.append(compound)\n",
    "                positive_list.append(pos)\n",
    "                neutral_list.append(neu)\n",
    "                negative_list.append(neg)\n",
    "                \n",
    "                # Set oldest tweet value\n",
    "                oldest_tweet = int(tweet[\"id_str\"]) - 1\n",
    "                \n",
    "                # Create a sentiments dictionary\n",
    "                sentiments.append({\"User\": target,\n",
    "                                   \"Tweet\": tweet[\"text\"],\n",
    "                                   \"Date\": tweet[\"created_at\"],\n",
    "                                   \"Compound\": compound,\n",
    "                                   \"Positive\": pos,\n",
    "                                   \"Neutral\": neu,\n",
    "                                   \"Negative\": neg,\n",
    "                                   \"Tweets Ago\": counter})\n",
    "                # Add to counter\n",
    "                counter = counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compound</th>\n",
       "      <th>Date</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Tweets Ago</th>\n",
       "      <th>User</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Mon Mar 12 00:47:29 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>@Gwenvev @KTHopkins @BBC The Orwell meter cont...</td>\n",
       "      <td>1</td>\n",
       "      <td>@BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>Mon Mar 12 00:46:53 +0000 2018</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.126</td>\n",
       "      <td>RT @BBC: Would you lay down your life for art?...</td>\n",
       "      <td>2</td>\n",
       "      <td>@BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8834</td>\n",
       "      <td>Mon Mar 12 00:46:41 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.377</td>\n",
       "      <td>RT @ldnsportingclub: In honour of #IWD2018, we...</td>\n",
       "      <td>3</td>\n",
       "      <td>@BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>Mon Mar 12 00:46:37 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.209</td>\n",
       "      <td>RT @BBC: ðŸ™Œ 1 year ago today the world became a...</td>\n",
       "      <td>4</td>\n",
       "      <td>@BBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4404</td>\n",
       "      <td>Mon Mar 12 00:46:10 +0000 2018</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.209</td>\n",
       "      <td>RT @BBC: ðŸ™Œ 1 year ago today the world became a...</td>\n",
       "      <td>5</td>\n",
       "      <td>@BBC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compound                            Date  Negative  Neutral  Positive  \\\n",
       "0    0.0000  Mon Mar 12 00:47:29 +0000 2018     0.000    1.000     0.000   \n",
       "1    0.0258  Mon Mar 12 00:46:53 +0000 2018     0.123    0.751     0.126   \n",
       "2    0.8834  Mon Mar 12 00:46:41 +0000 2018     0.000    0.623     0.377   \n",
       "3    0.4404  Mon Mar 12 00:46:37 +0000 2018     0.000    0.791     0.209   \n",
       "4    0.4404  Mon Mar 12 00:46:10 +0000 2018     0.000    0.791     0.209   \n",
       "\n",
       "                                               Tweet  Tweets Ago  User  \n",
       "0  @Gwenvev @KTHopkins @BBC The Orwell meter cont...           1  @BBC  \n",
       "1  RT @BBC: Would you lay down your life for art?...           2  @BBC  \n",
       "2  RT @ldnsportingclub: In honour of #IWD2018, we...           3  @BBC  \n",
       "3  RT @BBC: ðŸ™Œ 1 year ago today the world became a...           4  @BBC  \n",
       "4  RT @BBC: ðŸ™Œ 1 year ago today the world became a...           5  @BBC  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert sentiments to dataframe\n",
    "sentiments_pd = pd.DataFrame.from_dict(sentiments)\n",
    "sentiments_pd.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
